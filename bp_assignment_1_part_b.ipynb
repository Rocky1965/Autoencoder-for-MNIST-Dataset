{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSME Bonus Point Assignment I Part B\n",
    "<div style=\"text-align: right;font-size: 0.8em\">Document Version 1.0.1, released 2021-01-04</div>\n",
    "For task instructions, refer to the assignment PDF.\n",
    "\n",
    "* The parts of the code you are to implement are indicated via `# TODO` comments.\n",
    "* You can use the `# Test code` cells to verify your implementation. However note that these are not the unit tests used for grading.\n",
    "* Some cells create export file in the `solution/` folder. _Include whole `solution/` folder in your submission_.\n",
    "* DO NOT CLEAR THE OUTPUT of the notebook you are submitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Enable reproducibility\n",
    "torch.manual_seed(0)\n",
    "torch.set_deterministic(True)\n",
    "\n",
    "# Create solution folder\n",
    "Path(\"solution/\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you are missing dependencies (e.g. `ModuleNotFoundError: No module named ...`), run\n",
    "```sh\n",
    "conda install -y pandas seaborn scikit-learn pytorch torchvision cpuonly -c pytorch\n",
    "```\n",
    "in a terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question B1 - Data Preprocessing\n",
    "### a) Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Read CSV file\n",
    "# df = \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code\n",
    "assert 'df' in locals(), \"Variable df is not defined\"\n",
    "np.testing.assert_array_equal(df.columns, ['time', 'temperature', 'pressure','humidity', 'wind_speed', 'wind_deg', 'rain_1h', 'clouds_all', 'generation_solar'])\n",
    "np.testing.assert_equal(len(df), 30046)\n",
    "\"ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show histogram of pressure\n",
    "sns.histplot(data=df[\"pressure\"], discrete=True)\n",
    "plt.axvline(1050, c=\"black\", linestyle=\"dashed\",linewidth=1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Remove outliers from the data set\n",
    "# df_filtered =\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code\n",
    "assert 'df_filtered' in locals(), \"Variable df_filtered is not defined\"\n",
    "assert (df_filtered[\"pressure\"] <= 1050).all(), \"contains pressure > 1050\"\n",
    "assert (df_filtered[\"wind_speed\"] <= 30).all(), \"contains wind_speed > 30\"\n",
    "assert len(df_filtered) == 29731, \"Dropped too many rows\"\n",
    "\"ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Introduce day feature\n",
    "# df_filtered.loc[:, \"day\"] = \n",
    "\n",
    "\n",
    "\n",
    "# TODO Introduce generation_solar_categorical feature\n",
    "# df_filtered.loc[:, \"generation_solar_categorical\"] = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code\n",
    "assert all(df_filtered.loc[df_filtered[\"time\"] == \"2015-03-02 21:00:00\", \"day\"] == 61)\n",
    "assert all(df_filtered.loc[df_filtered[\"time\"] == \"2018-08-06 11:00:00\", \"day\"] == 218)\n",
    "\n",
    "assert all(df_filtered[\"generation_solar_categorical\"][df_filtered[\"generation_solar\"] < 160] == \"low\"), \"low label not correct\"\n",
    "assert all(df_filtered[\"generation_solar_categorical\"][(160 <= df_filtered[\"generation_solar\"]) & (df_filtered[\"generation_solar\"] < 1600)] == \"medium\"), \"medium label not correct\"\n",
    "assert all(df_filtered[\"generation_solar_categorical\"][1600 <= df_filtered[\"generation_solar\"]] == \"high\"), \"high label not correct\"\n",
    "\"ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Standardize the dataset\n",
    "# df_filtered = \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code\n",
    "assert \"time\" in df_filtered.columns\n",
    "assert \"generation_solar_categorical\" in df_filtered.columns\n",
    "\n",
    "for f in [\"temperature\", \"pressure\", \"humidity\", \"wind_speed\", \"wind_deg\", \"rain_1h\", \"clouds_all\", \"generation_solar\", \"day\"]:\n",
    "    assert np.isclose(np.mean(df_filtered[f]), 0), f\"{f} is not standardized\"\n",
    "    assert np.isclose(np.std(df_filtered[f]), 1), f\"{f} is not standardized\"\n",
    "\n",
    "\"ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Train/Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Train-validation split\n",
    "# df_train = \n",
    "# df_val =\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code\n",
    "assert len(df_train) == 26757, \"df_train has wrong size\"\n",
    "assert len(df_val) == 2974, \"df_test has wrong size\"\n",
    "assert not df_val.index.isin(df_train.index).any(), \"df_test and df_train not disjunct\"\n",
    "assert not df_train.index.isin(df_val.index).any(), \"df_test and df_train not disjunct\"\n",
    "\n",
    "# Export data sets\n",
    "df_train.to_csv(\"solution/b1e-train.csv\", index=False)\n",
    "df_val.to_csv(\"solution/b1e-val.csv\", index=False)\n",
    "\n",
    "\"ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question B2 - Modelling with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "predictors = [\"day\", \"temperature\", \"pressure\", \"humidity\", \"wind_speed\", \"wind_deg\", \"rain_1h\", \"clouds_all\"]\n",
    "target = \"generation_solar\"\n",
    "\n",
    "# ********************\n",
    "# TODO Fit linear model\n",
    "# model =\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Code\n",
    "assert \"model\" in locals(), \"Model not implemented\"\n",
    "assert model.coef_.shape == (8, ), \"Wrong number of predictors\"\n",
    "_pred = model.predict(df_val[predictors])\n",
    "sns.scatterplot(x=df_val[\"time\"], y=df_val[target])\n",
    "sns.scatterplot(x=df_val[\"time\"], y=_pred)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"solution/b2a.png\")\n",
    "mse = np.mean((_pred - df_val[target])**2)\n",
    "print(f\"MSE linear: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Linear regression with non-linear basis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# TODO Create polynomial feature transformation\n",
    "# poly =\n",
    "\n",
    "\n",
    "\n",
    "# TODO Fit linear model\n",
    "# model_poly =\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Code\n",
    "assert \"model_poly\" in locals(), \"model_poly not implemented\"\n",
    "_pred = model_poly.predict(poly.transform(df_val[predictors]))\n",
    "sns.scatterplot(x=df_val[\"time\"], y=df_val[target])\n",
    "sns.scatterplot(x=df_val[\"time\"], y=_pred)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"solution/b2b.png\")\n",
    "mse = np.mean((_pred - df_val[target])**2)\n",
    "print(f\"MSE poly: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "target = \"generation_solar_categorical\"\n",
    "\n",
    "# TODO Fit classifier\n",
    "# model_cls =\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Code\n",
    "assert \"model_cls\" in locals(), \"model_cls not implemented\"\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(df_val[target], model_cls.predict(df_val[predictors]), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question B3 - Modelling with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data loaders for PyTorch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "predictors = [\"day\", \"temperature\", \"pressure\", \"humidity\", \"wind_speed\", \"wind_deg\", \"rain_1h\", \"clouds_all\"]\n",
    "\n",
    "x_train = torch.tensor(df_train[predictors].values,  dtype=torch.float)\n",
    "x_val = torch.tensor(df_val[predictors].values,  dtype=torch.float)\n",
    "\n",
    "y_train = torch.tensor(df_train[[\"generation_solar\"]].values,  dtype=torch.float)\n",
    "y_val = torch.tensor(df_val[[\"generation_solar\"]].values,  dtype=torch.float)\n",
    "\n",
    "\n",
    "y_train_cat = torch.tensor(df_train[\"generation_solar_categorical\"].cat.codes.values.copy(),  dtype=torch.int64)\n",
    "y_val_cat = torch.tensor(df_val[\"generation_solar_categorical\"].cat.codes.values.copy(),  dtype=torch.int64)\n",
    "\n",
    "\n",
    "# For regression\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "\n",
    "# For classification\n",
    "dataset_cat = TensorDataset(x_train, y_train_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Build a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # TODO Create layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO Implement forward pass\n",
    "        \n",
    "        return x\n",
    "\n",
    "net = Net()  # changed 2021-01-04: This variable is now called net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code\n",
    "np.testing.assert_array_equal([p.nelement() for p in net.parameters()], [80, 10, 100, 10, 10, 1])\n",
    "np.testing.assert_array_equal(net(torch.zeros(32, 8)).shape, [32, 1])\n",
    "\"ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tune typerparameters \n",
    "# Hyperparameters\n",
    "learn_rate = 1e-4\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # TODO Create layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO Implement forward pass\n",
    "        \n",
    "        return x\n",
    "net = Net()\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learn_rate)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "losses = []\n",
    "with tqdm(range(epochs)) as pbar:\n",
    "    for epoch in pbar:  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(dataloader):\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item() * inputs.shape[0]\n",
    "        losses.append([running_loss / len(dataset), criterion(net(x_val), y_val).item()])\n",
    "        pbar.set_description(f\"MSE {losses[-1][0]:.02f}/{losses[-1][1]:.02f}\")\n",
    "\n",
    "# Save model\n",
    "with open(\"solution/b3b.pt\", \"wb\") as f:\n",
    "    torch.save(net, f)\n",
    "\n",
    "# Plot loss\n",
    "losses = np.array(losses)\n",
    "plt.plot(np.arange(len(losses)), losses[:,0], label=\"train\")\n",
    "plt.plot(np.arange(len(losses)), losses[:,1], label=\"validation\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"solution/b3b.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tune typerparameters \n",
    "# Hyperparameters\n",
    "learn_rate = 1e-4\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # TODO Create layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO Implement forward pass\n",
    "        \n",
    "        return x\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learn_rate)\n",
    "dataloader_cat = DataLoader(dataset_cat, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "losses=[]\n",
    "with tqdm(range(epochs)) as pbar:\n",
    "    for epoch in pbar:  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(dataloader_cat):\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item() * inputs.shape[0]\n",
    "        losses.append([running_loss / len(dataset), 1-torch.sum((torch.argmax(net(x_val), dim=1) == y_val_cat)) / len(x_val)])\n",
    "        pbar.set_description(f\"Loss {losses[-1][0]:.02f}/{losses[-1][1]:.02f}\")\n",
    "\n",
    "# Save model\n",
    "with open(\"solution/b3c.pt\", \"wb\") as f:\n",
    "    torch.save(net, f)\n",
    "\n",
    "# Plot loss\n",
    "losses = np.array(losses)\n",
    "plt.plot(np.arange(len(losses)), losses[:,0], label=\"train\")\n",
    "plt.plot(np.arange(len(losses)), losses[:,1], label=\"validation\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"solution/b3c.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model do you think is suited the best for modelling `generation_solar` and why? Please write down your answer below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
